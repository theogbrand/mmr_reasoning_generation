{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"HuggingFaceM4/RAVEN\", \"center_single\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['panels', 'choices', 'structure', 'meta_matrix', 'meta_target', 'meta_structure', 'target', 'id', 'metadata'],\n",
       "    num_rows: 6000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['panels', 'choices', 'structure', 'meta_matrix', 'meta_target', 'meta_structure', 'target', 'id', 'metadata']\n",
      "\n",
      "Panels shape: 8\n",
      "Choices shape: 8\n",
      "Target: 4\n",
      "ID: 3023\n",
      "\n",
      "First panel type: <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "First choice type: <class 'PIL.PngImagePlugin.PngImageFile'>\n"
     ]
    }
   ],
   "source": [
    "# Examine the structure of a single example\n",
    "example = ds[0]\n",
    "print(\"Keys:\", list(example.keys()))\n",
    "print(\"\\nPanels shape:\", len(example['panels']))\n",
    "print(\"Choices shape:\", len(example['choices']))\n",
    "print(\"Target:\", example['target'])\n",
    "print(\"ID:\", example['id'])\n",
    "\n",
    "# Look at the first panel and choice to understand the image format\n",
    "print(\"\\nFirst panel type:\", type(example['panels'][0]))\n",
    "print(\"First choice type:\", type(example['choices'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAVENRunner import...\n",
      "RAVENRunner class imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test the RAVENRunner class\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "from preprocessing.load_raven import RAVENRunner\n",
    "import os\n",
    "\n",
    "# Check if we can import and initialize (without real credentials)\n",
    "print(\"Testing RAVENRunner import...\")\n",
    "print(\"RAVENRunner class imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.load_raven:Loading RAVEN dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAVENRunner initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.load_raven:Loaded datasets: [('train', 6000), ('validation', 2000), ('test', 2000)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAVENRunner initialized successfully!\n",
      "✓ Loaded datasets: [('train', 6000), ('validation', 2000), ('test', 2000)]\n",
      "✓ Validation sample keys: ['panels', 'choices', 'structure', 'meta_matrix', 'meta_target', 'meta_structure', 'target', 'id', 'metadata']\n",
      "✓ Target: 4 (zero-indexed), ID: 5047\n",
      "✓ Target as 1-indexed choice: 5\n"
     ]
    }
   ],
   "source": [
    "# Test RAVENRunner initialization (won't actually call API)\n",
    "print(\"Testing RAVENRunner initialization...\")\n",
    "\n",
    "try:\n",
    "    # This will load the datasets but won't make API calls\n",
    "    runner = RAVENRunner(\n",
    "        model_name=\"azure/gpt-4.1\",\n",
    "        reasoning_effort=\"high\"\n",
    "    )\n",
    "    print(\"✓ RAVENRunner initialized successfully!\")\n",
    "    print(f\"✓ Loaded datasets: {[(k, len(v)) for k, v in runner.datasets.items()]}\")\n",
    "    \n",
    "    # Test dataset access\n",
    "    val_sample = runner.datasets['validation'][0]\n",
    "    print(f\"✓ Validation sample keys: {list(val_sample.keys())}\")\n",
    "    print(f\"✓ Target: {val_sample['target']} (zero-indexed), ID: {val_sample['id']}\")\n",
    "    print(f\"✓ Target as 1-indexed choice: {val_sample['target'] + 1}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://dalle-declare.openai.azure.com/openai/deployments/o4-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pattern is that each column keeps the same shape, each row the same size (big, medium, small), and the three fill‐levels (white, light‐gray, dark‐gray) rotate “down” each column.  In column 3 (the triangles) you have:\n",
      "\n",
      " Row 1: light‐gray  \n",
      " Row 2: dark‐gray  \n",
      " Row 3: must be white  \n",
      "\n",
      "And in row 3 everything is the small version.  Therefore you need the small, unfilled (white) triangle – that is choice 6.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
    "\n",
    "# Example usage\n",
    "image_path = 'test_combined_raven_image.png'\n",
    "data_url = local_image_to_data_url(image_path)\n",
    "# print(\"Data URL:\", data_url)\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "endpoint = \"https://dalle-declare.openai.azure.com/\"\n",
    "model_name = \"o4-mini\"\n",
    "deployment = \"o4-mini\"\n",
    "\n",
    "api_version = \"2025-01-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=os.getenv(\"AZURE_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What is the answer?\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    max_completion_tokens=100000,\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.load_raven:Loading RAVEN dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAVENRunner import...\n",
      "RAVENRunner class imported successfully!\n",
      "Testing NEW combined image approach...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.load_raven:Loaded datasets: [('train', 6000), ('validation', 2000), ('test', 2000)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created prompt with <PIL.Image.Image image mode=RGB size=848x1102 at 0x72FB788D8110> combined image(s) (should be 1)\n",
      "✓ Combined image size: (848, 1102)\n",
      "✓ Ground truth target: 4 (zero-indexed) = choice 5\n",
      "\n",
      "============================================================\n",
      "NEW COMBINED IMAGE PROMPT:\n",
      "============================================================\n",
      "You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your task is to identify which of the 8 numbered choices (1-8) best completes the pattern.\n",
      "\n",
      "Select the choice (1-8) that best completes the pattern. Respond with only the number (1, 2, 3, 4, 5, 6, 7, or 8).\n",
      "============================================================\n",
      "\n",
      "Displaying the combined image...\n",
      "✓ Saved combined image as 'test_combined_raven_image.png'\n",
      "\n",
      "Testing combined image encoding...\n",
      "✓ Successfully encoded combined image: 79404 chars\n",
      "✓ Encoded starts with: iVBORw0KGgoAAAANSUhEUgAAA1AAAA...\n",
      "\n",
      "Image dimensions:\n",
      "✓ Combined image: (848, 1102)\n",
      "✓ Width x Height: 848 x 1102 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "display-im6.q16: unable to open X server `' @ error/display.c/DisplayImageCommand/412.\n"
     ]
    }
   ],
   "source": [
    "# Test the RAVENRunner class\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "from preprocessing.load_raven import RAVENRunner\n",
    "import os\n",
    "\n",
    "# Check if we can import and initialize (without real credentials)\n",
    "print(\"Testing RAVENRunner import...\")\n",
    "print(\"RAVENRunner class imported successfully!\")\n",
    "\n",
    "# Test the NEW combined image approach (single image instead of two)\n",
    "print(\"Testing NEW combined image approach...\")\n",
    "\n",
    "# Initialize runner with updated code\n",
    "runner = RAVENRunner(model_name=\"azure/o4-mini\", reasoning_effort=\"high\")\n",
    "\n",
    "example = runner.datasets['validation'][0]\n",
    "prompt, combined_image = runner.create_raven_prompt(example['panels'], example['choices'])\n",
    "\n",
    "print(f\"✓ Created prompt with {combined_image} combined image(s) (should be 1)\")\n",
    "print(f\"✓ Combined image size: {combined_image.size}\")\n",
    "print(f\"✓ Ground truth target: {example['target']} (zero-indexed) = choice {example['target'] + 1}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEW COMBINED IMAGE PROMPT:\")\n",
    "print(\"=\"*60)\n",
    "print(prompt)\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display and save the combined image for visual inspection\n",
    "print(f\"\\nDisplaying the combined image...\")\n",
    "\n",
    "# Display the combined image (this will open in your default image viewer)\n",
    "combined_image.show()\n",
    "\n",
    "# Save the combined image for inspection\n",
    "combined_image.save(\"test_combined_raven_image.png\")\n",
    "print(\"✓ Saved combined image as 'test_combined_raven_image.png'\")\n",
    "\n",
    "# Test image encoding for API readiness\n",
    "print(f\"\\nTesting combined image encoding...\")\n",
    "encoded_image = runner.encode_image_to_base64(combined_image)\n",
    "print(f\"✓ Successfully encoded combined image: {len(encoded_image)} chars\")\n",
    "print(f\"✓ Encoded starts with: {encoded_image[:30]}...\")\n",
    "\n",
    "# Show dimensions comparison\n",
    "print(f\"\\nImage dimensions:\")\n",
    "print(f\"✓ Combined image: {combined_image.size}\")\n",
    "print(f\"✓ Width x Height: {combined_image.size[0]} x {combined_image.size[1]} pixels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single API call with combined image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://dalle-declare.openai.azure.com/openai/deployments/o4-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:llm_logger:RESPONSE: 7\n",
      "INFO:llm_logger:Added to cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API call successful!\n",
      "✓ Raw response: '7'\n",
      "✓ Parsed response: 6 (zero-indexed)\n",
      "✓ Model chose option: 7 (1-indexed)\n",
      "✓ Ground truth: 5 (1-indexed)\n",
      "✓ Correct: False\n"
     ]
    }
   ],
   "source": [
    "# Test a single API call with the combined image\n",
    "print(\"Testing single API call with combined image...\")\n",
    "\n",
    "try:\n",
    "    # Make a single API call to test the new combined image approach\n",
    "    response = runner.query_azure_openai(prompt, combined_image)\n",
    "    \n",
    "    print(f\"✓ API call successful!\")\n",
    "    print(f\"✓ Raw response: '{response}'\")\n",
    "    \n",
    "    # Parse the response\n",
    "    parsed_response = runner.parse_response(response)\n",
    "    print(f\"✓ Parsed response: {parsed_response} (zero-indexed)\")\n",
    "    \n",
    "    if parsed_response != -1:\n",
    "        print(f\"✓ Model chose option: {parsed_response + 1} (1-indexed)\")\n",
    "        print(f\"✓ Ground truth: {example['target'] + 1} (1-indexed)\")\n",
    "        print(f\"✓ Correct: {parsed_response == example['target']}\")\n",
    "    else:\n",
    "        print(\"✗ Invalid response - could not parse\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ API call failed: {e}\")\n",
    "    print(\"This might be due to missing API credentials or network issues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.load_raven:Loading RAVEN dataset...\n",
      "INFO:preprocessing.load_raven:Loaded datasets: [('train', 6000), ('validation', 2000), ('test', 2000)]\n",
      "INFO:preprocessing.load_raven:Evaluating 5 samples from validation split...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:preprocessing.load_raven:Detailed results saved to raven_results_validation_5samples.json\n",
      "INFO:preprocessing.load_raven:Batch evaluating 10 samples (batch_size=3)...\n",
      "INFO:preprocessing.load_raven:Processing batch 1: samples 0-2\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on 5 validation samples...\n",
      "Results:\n",
      "Accuracy: 0.200\n",
      "Correct: 1/5\n",
      "Invalid responses: 0\n",
      "Valid accuracy: 0.200\n",
      "\\nFor larger evaluations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:preprocessing.load_raven:Pausing between batches...\n",
      "INFO:preprocessing.load_raven:Processing batch 2: samples 3-5\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:preprocessing.load_raven:Pausing between batches...\n",
      "INFO:preprocessing.load_raven:Processing batch 3: samples 6-8\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:preprocessing.load_raven:Pausing between batches...\n",
      "INFO:preprocessing.load_raven:Processing batch 4: samples 9-9\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/gpt-4.1, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables for your chosen model:\n",
    "runner = RAVENRunner(model_name=\"azure/gpt-4.1\", reasoning_effort=\"high\")\n",
    "\n",
    "\n",
    "# Run small test evaluation\n",
    "print(\"Running evaluation on 5 validation samples...\")\n",
    "results = runner.evaluate_dataset(\"validation\", max_samples=5)\n",
    "\n",
    "print(f\"Results:\")\n",
    "print(f\"Accuracy: {results['accuracy']:.3f}\")\n",
    "print(f\"Correct: {results['correct']}/{results['total']}\")\n",
    "print(f\"Invalid responses: {results['invalid_responses']}\")\n",
    "print(f\"Valid accuracy: {results['valid_accuracy']:.3f}\")\n",
    "\n",
    "# For larger evaluations, use batch processing\n",
    "print(\"\\\\nFor larger evaluations:\")\n",
    "batch_results = runner.batch_evaluate(\"validation\", batch_size=3, max_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.load_raven:Loading RAVEN dataset...\n",
      "INFO:preprocessing.load_raven:Loaded datasets: [('train', 6000), ('validation', 2000), ('test', 2000)]\n",
      "INFO:preprocessing.load_raven:Evaluating 5 samples from validation split...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on 5 validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://dalle-declare.openai.azure.com/openai/deployments/o4-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:llm_logger:RESPONSE: 6\n",
      "INFO:llm_logger:Added to cache\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:preprocessing.load_raven:Detailed results saved to raven_results_validation_5samples.json\n",
      "INFO:preprocessing.load_raven:Batch evaluating 10 samples (batch_size=3)...\n",
      "INFO:preprocessing.load_raven:Processing batch 1: samples 0-2\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:preprocessing.load_raven:Pausing between batches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Accuracy: 0.000\n",
      "Correct: 0/5\n",
      "Invalid responses: 0\n",
      "Valid accuracy: 0.000\n",
      "\\nFor larger evaluations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.load_raven:Processing batch 2: samples 3-5\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:preprocessing.load_raven:Pausing between batches...\n",
      "INFO:preprocessing.load_raven:Processing batch 3: samples 6-8\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n",
      "INFO:preprocessing.load_raven:Pausing between batches...\n",
      "INFO:preprocessing.load_raven:Processing batch 4: samples 9-9\n",
      "INFO:llm_logger:PROMPT: You are shown a 3x3 matrix of images with the bottom-right panel missing (marked with \"?\"). Your tas...\n",
      "INFO:llm_logger:MODEL: azure/o4-mini, REASONING: high\n",
      "INFO:llm_logger:Cache hit for prompt: You are shown a 3x3 matrix of images with the bott...\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables for your chosen model:\n",
    "\n",
    "# Initialize runner\n",
    "runner = RAVENRunner(\n",
    "    model_name=\"azure/o4-mini\",  # or \"vertex_ai/claude-3-7-sonnet@20250219\"\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "\n",
    "# Run small test evaluation\n",
    "print(\"Running evaluation on 5 validation samples...\")\n",
    "results = runner.evaluate_dataset(\"validation\", max_samples=5)\n",
    "\n",
    "print(f\"Results:\")\n",
    "print(f\"Accuracy: {results['accuracy']:.3f}\")\n",
    "print(f\"Correct: {results['correct']}/{results['total']}\")\n",
    "print(f\"Invalid responses: {results['invalid_responses']}\")\n",
    "print(f\"Valid accuracy: {results['valid_accuracy']:.3f}\")\n",
    "\n",
    "# # For larger evaluations, use batch processing\n",
    "print(\"\\\\nFor larger evaluations:\")\n",
    "batch_results = runner.batch_evaluate(\"validation\", batch_size=3, max_samples=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
